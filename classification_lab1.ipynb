{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V9dsBtgXkzrl"
      },
      "outputs": [],
      "source": [
        "!pip install langchain_community\n",
        "!pip install replicate\n",
        "\n",
        "from langchain_community.llms import Replicate\n",
        "import os\n",
        "\n",
        "# Set the API token\n",
        "api_token = \"r8_AqhIkZALgLofe2ZjqFJrMkXAvMbC8cx0q8xNo\"\n",
        "os.environ[\"REPLICATE_API_TOKEN\"] = api_token\n",
        "\n",
        "# Define the customer reviews\n",
        "customer_reviews = [\n",
        "    \"The battery lasts all day, but the phone gets hot during gaming.\",\n",
        "    \"The screen is too dim outdoors, but I love the colors indoors.\",\n",
        "    \"This phone is fast, but it keeps crashing when I open certain apps.\"\n",
        "]\n",
        "\n",
        "# Refine the prompt to include reviews\n",
        "reviews_text = \"\\n\".join([f\"Review {i+1}: {review}\" for i, review in enumerate(customer_reviews)])\n",
        "prompt = f\"\"\"\n",
        "Classify these reviews as Positive, Negative, or Mixed:\n",
        "\n",
        "{reviews_text}\n",
        "\"\"\"\n",
        "\n",
        "# Model setup\n",
        "model = \"ibm-granite/granite-3.0-8b-instruct\"\n",
        "\n",
        "output = Replicate(\n",
        "    model=model,\n",
        "    replicate_api_token=api_token,\n",
        ")\n",
        "\n",
        "# Invoke the model with the refined prompt\n",
        "response = output.invoke(prompt)\n",
        "\n",
        "# Print the response\n",
        "print(\"Granite Model Response:\\n\")\n",
        "print(response)"
      ]
    }
  ]
}